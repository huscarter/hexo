---
title: 数据结构整理
date: 2020-81-09 20:18:44
categories: java
tags:
     - 数据结构
description: 整理目前java可能使用的数据结构。
---

### Collection<interface>

#### List<interface> extends Collection
1. Vector
 - 底层基于数组实现，多用于查询，线程安全（因为Vector的操作方法大多增加了synchronized锁） 
```
class Vectore extends AbstractList<E> implements List<E>, RandomAccess, Cloneable, java.io.Serializable{
    protected Object[] elementData; // 保存数据的数组
    protected int elementCount;// 实际数据的数量
    protected int capacityIncrement;// 容量增长系数

    Vector(){ // 默认构造函数
         this(10); // 默认的capacity容量大小
    }
    
    Vector(int capacity)// capacity是Vector的默认容量大小。当由于增加数据导致容量增加时，每次容量会增加一倍（Arrays.copyOf(elementData, newCapacity)）
    
    Vector(int capacity, int capacityIncrement)// capacity是Vector的默认容量大小，capacityIncrement是每次Vector容量增加时的增量值
    
    Vector(Collection<? extends E> collection)// 创建一个包含collection的Vector
}
```

2. ArrayList
 - 底层基于数组实现，多用于查询，线程不安全
```
private int size;  // 实际元素个数
transient Object[] elementData; // 保存数据的数组
// 增长系数为1.5，如果太小增赋值所需的容量，如果太大则赋值Integer.MAX_VALUE 
```

3. LinkedList
 - 底层基于链表实现，多用于插入和删除，线程不安全
 - 属于双联表，get(index)查询时会判断index和链表长度，超过一半从末尾查，小于一半从开始查。
```
public class LinkedList<E> extends AbstractSequentialList<E> implements List<E>, Deque<E>, Cloneable, java.io.Serializable{
    transient int size = 0;
    transient Node<E> first;
    
    transient Node<E> last;
    
    public LinkedList() {
        //
    }
    
    public LinkedList(Collection<? extends E> c) {
        this();
        addAll(c);
    }
    
    //
    private static class Node<E> {
        E item;
        Node<E> next;
        Node<E> prev;
        Node(Node<E> prev, E element, Node<E> next) {
            this.item = element;
            this.next = next;
            this.prev = prev;
        }
    }
}
```

#### Set<interface> extends Collection
1. HashSet
 - 无序存储数据，不能重复，可存储null，通底层过HashMap实现（将数据保存到HashMap的Key，value统一为Object()）。线程不安全。
```
public class HashSet<E> extends AbstractSet<E> implements Set<E>, Cloneable, java.io.Serializable {  
    static final long serialVersionUID = -5024744406713321676L;  
    private transient HashMap<E, Object> map;  // 底层使用HashMap来保存HashSet中所有元素。  
  
    private static final Object PRESENT = new Object();// 定义一个虚拟的Object对象作为HashMap的value，将此对象定义为static final。  
    public HashSet() {  
        map = new HashMap<E, Object>();  
    }  
    public boolean add(E e) {  
        return map.put(e, PRESENT) == null;  
    } 
```

2. TreeSet
 - 有序存储数据，不能重复，可以存储null，底层通过 TreeMap 实现，排序通过二叉树的排序实现。线程不安全。
 - 因为有顺序所以存储的对象需要实现Comparable接口、或者给TreeSet构造器传入Comparator实现类。
```
public class TreeSet<E> extends AbstractSet<E>    implements NavigableSet<E>, Cloneable, java.io.Serializable{
    private transient NavigableMap<E,Object> m;        //PRESENT会被当做Map的value与key构建成键值对 
    private static final Object PRESENT = new Object();
    
    TreeSet()// 默认构造函数。使用该构造函数，TreeSet中的元素按照自然排序进行排列。
    
    TreeSet(Comparator<? super E> comparator)// 指定TreeSet的比较器

    public boolean add(E e) {
        return m.put(e, PRESENT)==null;
    }
}
```

3. LinkedHashSet
 - 根据插入的顺序排列，不能重复，可以存储null，底层通过 LinkedHashMap 实现。线程不安全。
 
### Map

1. HashMap
 - 基于Map实现、可null键/值、非同步、不保证有序(比如插入的顺序)、也不保证顺序不随时间变化.
```
public class HashMap<K,V> extends AbstractMap<K, V> implements Map<K, V>, Cloneable, Serializable{
    static final int DEFAULT_INITIAL_CAPACITY = 16; // 默认存储容量
    static final int MAXIMUM_CAPACITY = 1073741824; // 2的31次方-1；
    static final float DEFAULT_LOAD_FACTOR = 0.75F; // 默认扩容因子
    static final int TREEIFY_THRESHOLD = 8; // 链表最大长度
    static final int MIN_TREEIFY_CAPACITY = 64; // 树形化最小容量（链表的4倍）
    transient HashMap.Node<K, V>[] table; // 存储数据的数组
    transient int size; // Node节点总数（数组+链表+树）
    int threshold; // = capacity（数组容量） * loadFactor（扩容因子）

    // 数组存储对象
    static class Node<K, V> implements Entry<K, V> {
            final int hash;
            final K key;
            V value;
            HashMap.Node<K, V> next; // 服务于链表
    
            Node(int hash, K key, V value, HashMap.Node<K, V> next) {
                this.hash = hash;
                this.key = key;
                this.value = value;
                this.next = next;
            }
    }
}
```
 - put数据过程
    - 第一次会初始化Node数组（默认长度16）；计算数组下表index，index位置没有值直接插入数据。
    - 如果index位置有值，判断hash和key是否相等，相等则覆盖原有Node。
    - 如果发生碰撞，判断该位置存放的是否是TreeNode，如果是调用TreeNode.putTreeVal插入树中
    - 如果不是TreeNode节点说明是链表，则添加至链表尾部。最后检查链表的长度是否超过链表阈值8，是的化将链表转为红黑树。
    - 只有原值覆盖会返回旧值，不会出发size++；否则都会size+1和阈值（threshold = capacity * loadFactor）比较，如果size大于阈值会进行扩容。
```
// 获取hash值
static final int hash(Object key) {
    int h;
    // 如果为 null 则返回的就是 0，否则就是 hashCode 异或上（hashCode 无符号右移 16 位）
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

// 获取index。自己抽离获取数组下表的方法，原HashMap类是没有的，单独拿出来方便记忆
// hash:hash(Object key);n:table.length
static final int index(int hash,int n){
    return hash & (n -1);// 按位与获得，等于（hash%n）
}

// HashMap的put方法最终会执行此方法
final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // tab为空则通过resize()创建，插入第 1 个值的时候发生
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 计算散列 index，没有冲突直接插入
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    // 有冲突
    else {
        Node<K,V> e; K k;
       // 存在 hash 值相同且 key 相等的，先记录下来，后面的插入步骤会使用新值将旧值替换掉
        if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        // 该节点为树，散列冲突过长，大于 TREEIFY_THRESHOLD = 8 时会转换成树
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        // 该节点为链表
        else {
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    // 插入到链尾
                    p.next = newNode(hash, key, value, null);
                    // 链表的长度超过 TREEIFY_THRESHOLD - 1 则转换成树
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                // 在链表中又相同的key，替换node
                if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        // 插入 existing mapping for key
        if (e != null) { 
            // 取出旧值，onlyIfAbsent此时为 false，所以不管 oldValue 有与否，都拿新值来替换
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 超过阈值 threshold = capacity * factor，调用 resize() 进行扩容
        resize();
    if (++size > threshold)
    afterNodeInsertion(evict);
    return null;
} // end putVal
```
 - 扩容过程（如果resize方法被调用意味着除了达到最大容量否则都会出发扩容或则初始化）
    - 如果是初始化，容量为默认的16，阈值threshold为capacity * loadFactor = 12。
    - 不是初始化，容量扩大1 倍，阈值也是扩大1倍。
    - 如果扩大的容量大于最大容量（2的30次方-1），取最大容量。
    - 如果当前容量已经为最大容量不扩容，通过碰撞存数据。
    - 创建扩容后数组，将原数组的数据移入新数组中，因为新组数的长度发生了变化所以存入的数据都需要重新计算index。
```
// 扩容会对性能会造成十分严重的影响，看下resize的具体内容
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        // 超过最大值就不再扩充 table，但并不表示不能插入了，只是后面的只能碰撞冲突了
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 没超过最大值，就扩充为原来的 2 倍。主要是容量以及阈值都为原来的 2倍。容量和阈值本身就都必须是 2 的幂，所以扩容的倍数必须是2的倍数，那么扩2倍就非常合理了。
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&  oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else { // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    // 计算新的resize阈值
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
    // 重新分配内存
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        // 把原来 tables 中的每个节点都移动到新的 tables 中
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)// 没有冲突，那重新计算下位置
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)// 冲突的是一棵树节点，分裂成 2 个树，或者如果树很小就转成链表
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order，冲突构成的是链表
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        // 索引不变
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        // 原索引+oldCap
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    // 原索引放到 tables 里
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    // 原索引+oldCap放到  tables 里
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
} // end resize
```
[参考](https://www.jianshu.com/p/0a70ce2d3b67)
[参考](https://www.cnblogs.com/LiaHon/p/11149644.html)

2. LinkedHashMap extends HashMap
 - 基于HashMap，并且通过增加head和tai以及自定义Entry（比Node多了before和after）实现双链表达到有序存储的功能。
```
public class LinkedHashMap<K, V> extends HashMap<K, V> implements Map<K, V> {
    transient LinkedHashMap.Entry<K, V> head; // 头节点
    transient LinkedHashMap.Entry<K, V> tail; // 尾节点
    final boolean accessOrder; // 是否通过访问调整顺序，true：访问过将对象放置最末尾

    // 自定义Entry
    static class Entry<K, V> extends Node<K, V> {
        LinkedHashMap.Entry<K, V> before; // 前一节点
        LinkedHashMap.Entry<K, V> after; // 下一个节点

        Entry(int var1, K var2, V var3, Node<K, V> var4) {
            super(var1, var2, var3, var4);
        }
    }
}
```
 - put对象和HashMap的put的逻辑一样，区别是在newNode(hash, key, value, null)方法。
```
Node<K,V> newNode(int hash, K key, V value, Node<K,V> e) {
    LinkedHashMap.Entry<K,V> p = new LinkedHashMap.Entry<K,V>(hash, key, value, e);
    // 调用此方法将存储的对象放置链表末尾
    linkNodeLast(p);
    return p;
}
// 放置末尾方法，服务于putVal方法，无视 accessOrder 属性
private void linkNodeLast(LinkedHashMap.Entry<K,V> p) {
    LinkedHashMap.Entry<K,V> last = tail;
    tail = p;
    if (last == null)
        head = p;
    else {
        p.before = last;
        last.after = p;
    }
}
```
 - get方法和HashMap的区别是多了 accessOrder 的逻辑，如果accessOrder为true会调用afterNodeAccess方法。
```
public V get(Object key) {
    Node<K,V> e;
    if ((e = getNode(hash(key), key)) == null)
        return null;
    if (accessOrder)
        afterNodeAccess(e);
    return e.value;
}
// 总结一点就是将访问的当前对象放到最末尾，只有在accessOrder==true时起作用。
void afterNodeAccess(Node<K,V> e) {
    //在执行方法前的上一次的尾结点
    LinkedHashMap.Entry<K,V> last;
    //当accessOrder为true并且传入的节点并不是上一次的尾结点时,执行下面的方法
    if (accessOrder && (last = tail) != e) {
        LinkedHashMap.Entry<K,V> p = (LinkedHashMap.Entry<K,V>)e, b = p.before, a = p.after;
        //p：当前节点，b：当前节点的前一个节点，a：当前节点的后一个节点；
        p.after = null;
        if (b == null)
            head = a;
        else
            b.after = a;
        if (a != null)
            a.before = b;
        else
            last = b;
        if (last == null)
            head = p;
        else {
            p.before = last;
            last.after = p;
        }
        tail = p;
        ++modCount;
    }
}
```

 - 移除链表中最老的对象，但在JDK8中不会执行。
```
void afterNodeInsertion(boolean evict) { // possibly remove eldest
    LinkedHashMap.Entry<K,V> first;
    if (evict && (first = head) != null && removeEldestEntry(first)) {
        K key = first.key;
        removeNode(hash(key), key, null, false, true);
    }
}
// 如有需要，请自己重写此返回值
protected boolean removeEldestEntry(Map.Entry<K,V> eldest) {
    return false;
}
```
[参考](https://www.cnblogs.com/LiaHon/p/11180869.html)

3. TreeMap（会有Key值的比较器，使用默认比较器时Key值不能为null）
 - 基于红黑树存储的Map（底层没有数组），通过Key值比较大小，也可以自己传入Comparator比较器。
 - HashMap适用于快速查找，LinkedHashMap适用于按操作顺序查找，TreeMap适用于按排序的统计查找。
```
public class TreeMap<K, V> extends AbstractMap<K, V> implements NavigableMap<K, V>, Cloneable, Serializable {
    private final Comparator<? super K> comparator; // 比较器
    private transient TreeMap.Entry<K, V> root; // 根节点
    private transient int size = 0; // entry个数
    private transient TreeMap<K, V>.EntrySet entrySet;
    private transient TreeMap.KeySet<K> navigableKeySet;
    private transient NavigableMap<K, V> descendingMap;
    private static final boolean RED = false;
    private static final boolean BLACK = true;

    static final class Entry<K, V> implements java.util.Map.Entry<K, V> {
        K key;
        V value;
        TreeMap.Entry<K, V> left;
        TreeMap.Entry<K, V> right;
        TreeMap.Entry<K, V> parent;
        boolean isBlck = true;

        Entry(K var1, V var2, TreeMap.Entry<K, V> var3) {
            this.key = var1;
            this.value = var2;
            this.parent = var3;
        }
    }
}
```
 - put对象，就是将entry插入到红黑树的过程
    - 如果是第一次插入，作为跟节点即可。
    - 不是第一次查找是否，通过比较器二分法查找key值相同的节点进行替换
    - 没有相同的key节点，在末尾插入节点
    - 调用fixAfterInsertion进行红黑树的合规维护。
```
public V put(K key, V value) {
    Entry<K,V> t = root;
    // 如果根节点都为null，还没建立起来红黑树，我们先new Entry并赋值给root把红黑树建立起来，这个时候红黑树中已经有一个节点了，同时修改操作+1。
    if (t == null) {
        compare(key, key); 
        root = new Entry<>(key, value, null);
        size = 1;
        modCount++;
        return null;
    }
    // 如果节点不为null,定义一个cmp，这个变量用来进行二分查找时的比较；定义parent，是new Entry时必须要的参数
    int cmp;
    Entry<K,V> parent;
    // cpr表示有无自己定义的排序规则，分两种情况遍历执行
    Comparator<? super K> cpr = comparator;
    if (cpr != null) {
        /**
         * 从root节点开始遍历，通过二分查找逐步向下找
         * 第一次循环：从根节点开始，这个时候parent就是根节点，然后通过自定义的排序算法
         * cpr.compare(key, t.key)比较传入的key和根节点的key值，如果传入的key<root.key，那么
         * 继续在root的左子树中找，从root的左孩子节点（root.left）开始：如果传入的key>root.key,
         * 那么继续在root的右子树中找，从root的右孩子节点（root.right）开始;如果恰好key==root.key，
         * 那么直接根据root节点的value值即可。
         * 后面的循环规则一样，当遍历到的当前节点作为起始节点，逐步往下找
         *
         * 需要注意的是：这里并没有对key是否为null进行判断，建议自己的实现Comparator时应该要考虑在内
         */
        do {
            parent = t;
            cmp = cpr.compare(key, t.key);
            if (cmp < 0)
                t = t.left;
            else if (cmp > 0)
                t = t.right;
            else
                return t.setValue(value);
        } while (t != null);
    }
    else {
        //从这里看出，当默认排序时，key值是不能为null的
        if (key == null)
            throw new NullPointerException();
        @SuppressWarnings("unchecked")
        Comparable<? super K> k = (Comparable<? super K>) key;
        //这里的实现逻辑和上面一样，都是通过二分查找，就不再多说了
        do {
            parent = t;
            cmp = k.compareTo(t.key);
            if (cmp < 0)
                t = t.left;
            else if (cmp > 0)
                t = t.right;
            else
                return t.setValue(value);
        } while (t != null);
    }
    /**
     * 能执行到这里，说明前面并没有找到相同的key,节点已经遍历到最后了，我们只需要new一个Entry放到
     * parent下面即可，但放到左子节点上还是右子节点上，就需要按照红黑树的规则来。
     */
    Entry<K,V> e = new Entry<>(key, value, parent);
    if (cmp < 0)
        parent.left = e;
    else
        parent.right = e;
    /**
     * 节点加进去了，并不算完，我们在前面红黑树原理章节提到过，一般情况下加入节点都会对红黑树的结构造成
     * 破坏，我们需要通过一些操作来进行自动平衡处置，如【变色】【左旋】【右旋】
     */
    fixAfterInsertion(e);
    size++;
    modCount++;
    return null;
}
```
 - get数据，就是红黑树的查找。

[参考](https://www.cnblogs.com/LiaHon/p/11221634.html)

4. Hashtable（线程安全，key、value都不能为null）
 - Hashtable 是针对 HashMap 线程安全的一种实现（在操作方法前添加了Synchronized关键字）
 - 由于会直接调用key.hashCode，key不能为null；在put方法总会判断value == null而抛出异常，所以value也不能为null
 - 数组索引方式和HashMap不一样（HashTable底层的扩容方式不一样，是通过hashCode & 0x7FFFFFFF) % tab.length）
 - 扩容方式和HashMap不一样（默认容量为11，扩容为原来的2倍+1）
```
public class Hashtable<K, V> extends Dictionary<K, V> implements Map<K, V>, Cloneable, Serializable {
    private transient Hashtable.Entry<?, ?>[] table;
    private transient int count;
    private int threshold;
    private float loadFactor;
    private transient int modCount;
    private static final int MAX_ARRAY_SIZE = 2147483639;
    private transient volatile Set<K> keySet;
    private transient volatile Set<java.util.Map.Entry<K, V>> entrySet;
    private transient volatile Collection<V> values;
    private static final int KEYS = 0;
    private static final int VALUES = 1;
    private static final int ENTRIES = 2;

    private static class Entry<K, V> implements java.util.Map.Entry<K, V> {
        final int hash;
        final K key;
        V value;
        Hashtable.Entry<K, V> next;

        protected Entry(int var1, K var2, V var3, Hashtable.Entry<K, V> var4) {
            this.hash = var1;
            this.key = var2;
            this.value = var3;
            this.next = var4;
        }
    }
}
```

5. ConcurrentHashMap
- 

### Linked<一种设计思想>

#### 单链表

#### 双链表

### 树结构

#### 二叉(查找\搜索)树
一般使用二叉的排序树，否则查询和插入和深度就不是O(1)而是O(n)
```
1. 左子树上所有节点的值均小于它的根节点的值;
2. 右子树上所有节点的值均大于它的根节点的值。
```

1. 平衡二叉树（AVL）
二叉排序树因为插入的顺序有可能编程一个链表(比如顺序为1、2、3)，为了避免此情况发生而出现了平衡二叉树
```
1. 要求两个子树的高度差不能超过1;
2. 每次增删都会通过一次或多次旋转来平衡二叉树。
 - 插入到不平衡节点左子树的左边需要RR（右旋）
 - 插入到不平衡节点又子树的右边需要LL（左旋）
 - 插入到不平衡节点左子树的右边需要LR（先左再右旋）
 - 插入到不平衡节点右子树的左边需要RL（先右再左旋）
```
[参考](https://baijiahao.baidu.com/s?id=1646617486319372351&wfr=spider&for=pc)
[参考](https://www.jianshu.com/p/f556f7fa6f35)

2. 红黑树（R-B Tree）
在大量查找的情况下，平衡二叉树的效率更高，也是首要选择。在大量增删的情况下平衡二叉树需要多次旋转，红黑树最多3此旋转是首选。
Java集合中的TreeSet和TreeMap，以及Linux虚拟内存的管理，都是通过红黑树去实现的
```
1. 节点要么黑要么红；
2. 根节点一定时黑色；
3. 所有叶节点都为null，且为黑色；
4. 红色节点的两个子节点都为黑色，不会有两个连续的红；
5. 任意一个路径上的黑节点数，一定时相等的。
```
[参考](https://baijiahao.baidu.com/s?id=1645429373049393021&wfr=spider&for=pc)

#### 多路树

1. B-Trees（平衡多路查找树，b为balance）
主要使用在文件系统中。
```
1. 每个节点最多有m个孩子。 
2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。 
3. 若根节点不是叶子节点，则至少有2个孩子 
4. 所有叶子节点都在同一层，且不包含其它关键字信息 
5. 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn）
6. 关键字的个数n满足：ceil(m/2)-1 <= n <= m-1 
7. ki(i=1,…n)为关键字，且关键字升序排序。 
8. Pi(i=1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)
```

2. B+Trees
所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息；实现文件索引结构方面比B树使用得更普遍
```
1. 非叶子节点只存储键值信息。
2. 所有叶子节点之间都有一个链指针。
3. 数据记录都存放在叶子节点中。
```

### 栈栈(先进后出)

### 队列（队列先进先出）
1. ArrayDeque

### android单独的数据结构
1. SparseArray

2. Pair


