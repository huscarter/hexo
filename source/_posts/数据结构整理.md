---
title: 数据结构整理
date: 2020-81-09 20:18:44
categories: java
tags:
     - 数据结构
description: 数据结构整理。
---

### Collection<interface>

#### List<interface> extends Collection
1. Vector
 - 多用于查询，线程安全（因为Vector的操作方法大多增加了synchronized锁） 
```
class Vectore extends AbstractList<E> implements List<E>, RandomAccess, Cloneable, java.io.Serializable{
    protected Object[] elementData; // 保存数据的数组
    protected int elementCount;// 实际数据的数量
    protected int capacityIncrement;// 容量增长系数

    Vector(){ // 默认构造函数
         this(10); // 默认的capacity容量大小
    }
    
    Vector(int capacity)// capacity是Vector的默认容量大小。当由于增加数据导致容量增加时，每次容量会增加一倍（Arrays.copyOf(elementData, newCapacity)）
    
    Vector(int capacity, int capacityIncrement)// capacity是Vector的默认容量大小，capacityIncrement是每次Vector容量增加时的增量值
    
    Vector(Collection<? extends E> collection)// 创建一个包含collection的Vector
}
```

2. ArrayList
 - 多用于查询，线程不安全
```
private int size;  // 实际元素个数
transient Object[] elementData; // 保存数据的数组
// 增长系数为1.5，如果太小增赋值所需的容量，如果太大则赋值Integer.MAX_VALUE 
```

3. LinkedList
 - 多用于插入和删除，线程不安全
 - 属于双联表，get(index)查询时会判断index和链表长度，超过一半从末尾查，小于一半从开始查。
```
public class LinkedList<E> extends AbstractSequentialList<E> implements List<E>, Deque<E>, Cloneable, java.io.Serializable{
    transient int size = 0;
    transient Node<E> first;
    
    transient Node<E> last;
    
    public LinkedList() {
        //
    }
    
    public LinkedList(Collection<? extends E> c) {
        this();
        addAll(c);
    }
    
    //
    private static class Node<E> {
        E item;
        Node<E> next;
        Node<E> prev;
        Node(Node<E> prev, E element, Node<E> next) {
            this.item = element;
            this.next = next;
            this.prev = prev;
        }
    }
}
```

#### Set<interface> extends Collection
1. HashSet
 - 无序存储数据，不能重复，可存储null，通底层过HashMap实现（将数据保存到HashMap的Key，value统一为Object()）。线程不安全。
```
public class HashSet<E> extends AbstractSet<E> implements Set<E>, Cloneable, java.io.Serializable {  
    static final long serialVersionUID = -5024744406713321676L;  
    private transient HashMap<E, Object> map;  // 底层使用HashMap来保存HashSet中所有元素。  
  
    private static final Object PRESENT = new Object();// 定义一个虚拟的Object对象作为HashMap的value，将此对象定义为static final。  
    public HashSet() {  
        map = new HashMap<E, Object>();  
    }  
    public boolean add(E e) {  
        return map.put(e, PRESENT) == null;  
    } 
```

2. TreeSet
 - 有序存储数据，不能重复，可以存储null，底层通过 TreeMap 实现，排序通过二叉树的排序实现。线程不安全。
 - 因为有顺序所以存储的对象需要实现Comparable接口、或者给TreeSet构造器传入Comparator实现类。
```
public class TreeSet<E> extends AbstractSet<E>    implements NavigableSet<E>, Cloneable, java.io.Serializable{
    private transient NavigableMap<E,Object> m;        //PRESENT会被当做Map的value与key构建成键值对 
    private static final Object PRESENT = new Object();
    
    TreeSet()// 默认构造函数。使用该构造函数，TreeSet中的元素按照自然排序进行排列。
    
    TreeSet(Comparator<? super E> comparator)// 指定TreeSet的比较器

    public boolean add(E e) {
        return m.put(e, PRESENT)==null;
    }
}
```

3. LinkedHashSet
 - 根据插入的顺序排列，不能重复，可以存储null，底层通过 LinkedHashMap 实现。线程不安全。
 
### Map

1. HashMap
 - 基于Map实现、可null键/值、非同步、不保证有序(比如插入的顺序)、也不保证顺序不随时间变化.
```
public class HashMap<K,V> extends AbstractMap<K, V> implements Map<K, V>, Cloneable, Serializable{
    static final int DEFAULT_INITIAL_CAPACITY = 16; // 默认存储容量
    static final int MAXIMUM_CAPACITY = 1073741824; // 2的31次方-1；
    static final float DEFAULT_LOAD_FACTOR = 0.75F; // 默认扩容因子
    static final int TREEIFY_THRESHOLD = 8; // 链表最大长度
    static final int MIN_TREEIFY_CAPACITY = 64; // 树形化最小容量（链表的4倍）
    transient HashMap.Node<K, V>[] table; // 存储数据的数组
    transient int size; // Node节点总数（数组+链表+树）
    int threshold; // = capacity（数组容量） * loadFactor（扩容因子）

    // 数组存储对象
    static class Node<K, V> implements Entry<K, V> {
            final int hash;
            final K key;
            V value;
            HashMap.Node<K, V> next; // 服务于链表
    
            Node(int hash, K key, V value, HashMap.Node<K, V> next) {
                this.hash = hash;
                this.key = key;
                this.value = value;
                this.next = next;
            }
    }
}
```
 - put数据过程
    - 第一次会初始化Node数组（默认长度16）；计算数组下表index，index位置没有值直接插入数据。
    - 如果index位置有值，判断hash和key是否相等，相等则覆盖原有Node。
    - 如果发生碰撞，判断该位置存放的是否是TreeNode，如果是调用TreeNode.putTreeVal插入树中
    - 如果不是TreeNode节点说明是链表，则添加至链表尾部。最后检查链表的长度是否超过链表阈值8，是的化将链表转为红黑树。
    - 只有原值覆盖会返回旧值，不会出发size++；否则都会size+1和阈值（threshold = capacity * loadFactor）比较，如果size大于阈值会进行扩容。
```
// 获取hash值
static final int hash(Object key) {
    int h;
    // 如果为 null 则返回的就是 0，否则就是 hashCode 异或上（hashCode 无符号右移 16 位）
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}

// 获取index。自己抽离获取数组下表的方法，原HashMap类是没有的，单独拿出来方便记忆
// hash:hash(Object key);n:table.length
static final int index(int hash,int n){
    return hash & (n -1);// 按位与获得，等于（hash%n）
}

// HashMap的put方法最终会执行此方法
final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) {
    Node<K,V>[] tab; Node<K,V> p; int n, i;
    // tab为空则通过resize()创建，插入第 1 个值的时候发生
    if ((tab = table) == null || (n = tab.length) == 0)
        n = (tab = resize()).length;
    // 计算散列 index，没有冲突直接插入
    if ((p = tab[i = (n - 1) & hash]) == null)
        tab[i] = newNode(hash, key, value, null);
    // 有冲突
    else {
        Node<K,V> e; K k;
       // 存在 hash 值相同且 key 相等的，先记录下来，后面的插入步骤会使用新值将旧值替换掉
        if (p.hash == hash && ((k = p.key) == key || (key != null && key.equals(k))))
            e = p;
        // 该节点为树，散列冲突过长，大于 TREEIFY_THRESHOLD = 8 时会转换成树
        else if (p instanceof TreeNode)
            e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
        // 该节点为链表
        else {
            for (int binCount = 0; ; ++binCount) {
                if ((e = p.next) == null) {
                    // 插入到链尾
                    p.next = newNode(hash, key, value, null);
                    // 链表的长度超过 TREEIFY_THRESHOLD - 1 则转换成树
                    if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                        treeifyBin(tab, hash);
                    break;
                }
                // 对链表中的相同 hash 值且 key 相同的进一步作检查
                if (e.hash == hash && ((k = e.key) == key || (key != null && key.equals(k))))
                    break;
                p = e;
            }
        }
        // 插入 existing mapping for key
        if (e != null) { 
            // 取出旧值，onlyIfAbsent此时为 false，所以不管 oldValue 有与否，都拿新值来替换
            V oldValue = e.value;
            if (!onlyIfAbsent || oldValue == null)
                e.value = value;
            afterNodeAccess(e);
            return oldValue;
        }
    }
    ++modCount;
    // 超过阈值 threshold = capacity * factor，调用 resize() 进行扩容
        resize();
    if (++size > threshold)
    afterNodeInsertion(evict);
    return null;
} // end putVal
```
 - 扩容过程（如果resize方法被调用意味着除了达到最大容量否则都会出发扩容或则初始化）
    - 如果是初始化，容量为默认的16，阈值threshold为capacity * loadFactor = 12。
    - 不是初始化，容量扩大1 倍，阈值也是扩大1倍。
    - 如果扩大的容量大于最大容量（2的30次方-1），取最大容量。
    - 如果当前容量已经为最大容量不扩容，通过碰撞存数据。
    - 创建扩容后数组，将原数组的数据移入新数组中，因为新组数的长度发生了变化所以存入的数据都需要重新计算index。
```
// 扩容会对性能会造成十分严重的影响，看下resize的具体内容
final Node<K,V>[] resize() {
    Node<K,V>[] oldTab = table;
    int oldCap = (oldTab == null) ? 0 : oldTab.length;
    int oldThr = threshold;
    int newCap, newThr = 0;
    if (oldCap > 0) {
        // 超过最大值就不再扩充 table，但并不表示不能插入了，只是后面的只能碰撞冲突了
        if (oldCap >= MAXIMUM_CAPACITY) {
            threshold = Integer.MAX_VALUE;
            return oldTab;
        }
        // 没超过最大值，就扩充为原来的 2 倍。主要是容量以及阈值都为原来的 2倍。容量和阈值本身就都必须是 2 的幂，所以扩容的倍数必须是2的倍数，那么扩2倍就非常合理了。
        else if ((newCap = oldCap << 1) < MAXIMUM_CAPACITY &&  oldCap >= DEFAULT_INITIAL_CAPACITY)
            newThr = oldThr << 1; // double threshold
    }
    else if (oldThr > 0) // initial capacity was placed in threshold
        newCap = oldThr;
    else { // zero initial threshold signifies using defaults
        newCap = DEFAULT_INITIAL_CAPACITY;
        newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY);
    }
    // 计算新的resize阈值
    if (newThr == 0) {
        float ft = (float)newCap * loadFactor;
        newThr = (newCap < MAXIMUM_CAPACITY && ft < (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE);
    }
    threshold = newThr;
    @SuppressWarnings({"rawtypes","unchecked"})
    // 重新分配内存
    Node<K,V>[] newTab = (Node<K,V>[])new Node[newCap];
    table = newTab;
    if (oldTab != null) {
        // 把原来 tables 中的每个节点都移动到新的 tables 中
        for (int j = 0; j < oldCap; ++j) {
            Node<K,V> e;
            if ((e = oldTab[j]) != null) {
                oldTab[j] = null;
                if (e.next == null)// 没有冲突，那重新计算下位置
                    newTab[e.hash & (newCap - 1)] = e;
                else if (e instanceof TreeNode)// 冲突的是一棵树节点，分裂成 2 个树，或者如果树很小就转成链表
                    ((TreeNode<K,V>)e).split(this, newTab, j, oldCap);
                else { // preserve order，冲突构成的是链表
                    Node<K,V> loHead = null, loTail = null;
                    Node<K,V> hiHead = null, hiTail = null;
                    Node<K,V> next;
                    do {
                        next = e.next;
                        // 索引不变
                        if ((e.hash & oldCap) == 0) {
                            if (loTail == null)
                                loHead = e;
                            else
                                loTail.next = e;
                            loTail = e;
                        }
                        // 原索引+oldCap
                        else {
                            if (hiTail == null)
                                hiHead = e;
                            else
                                hiTail.next = e;
                            hiTail = e;
                        }
                    } while ((e = next) != null);
                    // 原索引放到 tables 里
                    if (loTail != null) {
                        loTail.next = null;
                        newTab[j] = loHead;
                    }
                    // 原索引+oldCap放到  tables 里
                    if (hiTail != null) {
                        hiTail.next = null;
                        newTab[j + oldCap] = hiHead;
                    }
                }
            }
        }
    }
    return newTab;
} // end resize
```
 
[参考](https://www.jianshu.com/p/0a70ce2d3b67)

2. TreeMap

3. HashTable

4. ConcurrentHashMap

5. LinkedHashMap extends HashMap

### Linked<一种设计思想>

#### 单链表

#### 双链表

### 树结构

#### 二叉(查找\搜索)树
一般使用二叉的排序树，否则查询和插入和深度就不是O(1)而是O(n)
```
1. 左子树上所有节点的值均小于它的根节点的值;
2. 右子树上所有节点的值均大于它的根节点的值。
```

1. 平衡二叉树（AVL）
二叉排序树因为插入的顺序有可能编程一个链表(比如顺序为1、2、3)，为了避免此情况发生而出现了平衡二叉树
```
1. 要求两个子树的高度差不能超过1;
2. 每次增删都会通过一次或多次旋转来平衡二叉树。
 - 插入到不平衡节点左子树的左边需要RR（右旋）
 - 插入到不平衡节点又子树的右边需要LL（左旋）
 - 插入到不平衡节点左子树的右边需要LR（先左再右旋）
 - 插入到不平衡节点右子树的左边需要RL（先右再左旋）
```
[参考](https://baijiahao.baidu.com/s?id=1646617486319372351&wfr=spider&for=pc)
[参考](https://www.jianshu.com/p/f556f7fa6f35)

2. 红黑树（R-B Tree）
在大量查找的情况下，平衡二叉树的效率更高，也是首要选择。在大量增删的情况下平衡二叉树需要多次旋转，红黑树最多3此旋转是首选。
Java集合中的TreeSet和TreeMap，以及Linux虚拟内存的管理，都是通过红黑树去实现的
```
1. 节点要么黑要么红；
2. 根节点一定时黑色；
3. 所有叶节点都为null，且为黑色；
4. 红色节点的两个子节点都为黑色，不会有两个连续的红；
5. 任意一个路径上的黑节点数，一定时相等的。
```
[参考](https://baijiahao.baidu.com/s?id=1645429373049393021&wfr=spider&for=pc)

#### 多路树

1. B-Trees（平衡多路查找树，b为balance）
主要使用在文件系统中。
```
1. 每个节点最多有m个孩子。 
2. 除了根节点和叶子节点外，其它每个节点至少有Ceil(m/2)个孩子。 
3. 若根节点不是叶子节点，则至少有2个孩子 
4. 所有叶子节点都在同一层，且不包含其它关键字信息 
5. 每个非终端节点包含n个关键字信息（P0,P1,…Pn, k1,…kn） 
6. 关键字的个数n满足：ceil(m/2)-1 <= n <= m-1 
7. ki(i=1,…n)为关键字，且关键字升序排序。 
8. Pi(i=1,…n)为指向子树根节点的指针。P(i-1)指向的子树的所有节点关键字均小于ki，但都大于k(i-1)
```

2. B+Trees
所有数据记录节点都是按照键值大小顺序存放在同一层的叶子节点上，而非叶子节点上只存储key值信息；实现文件索引结构方面比B树使用得更普遍
```
1. 非叶子节点只存储键值信息。
2. 所有叶子节点之间都有一个链指针。
3. 数据记录都存放在叶子节点中。
```

### 栈和队列（栈先进后出、队列先进先出）

### android单独的数据结构
1. SparseArray

2. Pair


